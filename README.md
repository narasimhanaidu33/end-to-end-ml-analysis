# End-to-End Machine Learning Analysis: Clustering, Classification & Regression

This repository contains an end-to-end machine learning project completed as part of MSc coursework.  
The project demonstrates a full data science workflow including exploratory data analysis, unsupervised learning, supervised classification, regression, model tuning, and evaluation.

---

## üìå Project Overview

The objective of this project is to analyse a biological dataset using multiple machine learning techniques to:

- Discover natural groupings in the data (clustering)
- Classify observations into known categories
- Predict a continuous outcome using regression
- Compare models based on performance and interpretability

The analysis emphasises **model evaluation, interpretability, and clear communication of insights**.

---

## üîç Key Stages of the Project

### 1. Exploratory Data Analysis (EDA)
- Data inspection and cleaning
- Distribution analysis (histograms, boxplots)
- Outlier detection
- Correlation analysis
- Insight-driven visualisations

### 2. Unsupervised Learning (Clustering)
- K-Means clustering
- Elbow Method and Silhouette Score
- PCA-based visualisation
- Cluster interpretation and validation

### 3. Supervised Classification
- Decision Tree (baseline, tuned, pruned)
- K-Nearest Neighbours (KNN)
- Logistic Regression
- Random Forest
- Model comparison using accuracy, precision, recall, and F1-score

### 4. Regression Analysis
- Linear Regression
- R¬≤, MAE, RMSE evaluation
- Interpretation of regression coefficients
- Discussion of model fit

---

## üß† Techniques & Models Used

- K-Means Clustering
- Decision Tree Classifier
- K-Nearest Neighbours (KNN)
- Logistic Regression (Multinomial)
- Random Forest Classifier
- Linear Regression
- PCA (for visualisation)
- GridSearchCV & Cost-Complexity Pruning

---

## üõ†Ô∏è Tools & Technologies

- **Python**
- pandas, NumPy
- matplotlib, seaborn
- scikit-learn
- Jupyter Notebook

---

## üìä Key Outcomes

- Strong natural separability identified through clustering
- Classification accuracy up to **~89.5%**
- Linear regression explained **~76% variance** in the target variable
- Feature importance and coefficients aligned with domain intuition
- Clear trade-off analysis between interpretability and performance


